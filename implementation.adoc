= Nextflow Implementaton

== Data preparation

A first step in any pipeline is to prepare the input data. You will find
all the data required to run the pipeline in the folder `data`
within the `ngs2017-nf` repository directory.

There are four data inputs that we will use in this tutorial:

. *Genome File* (`data/genome.fa`)
* Human chromosome 22 in FASTA file format

. *Read Files* (`data/reads/`)
* Sample ENCSR000COQ: 76bp paired-end reads (`ENCSR000COQ1_1.fq.gz` and `ENCSR000COQ1_2.fq.gz`).

. *Variants File* (`data/known_variants.vcf.gz`)
* Known variants, gunzipped as a Variant Calling File (VCF) format.

. *Blacklist File* (`data/blacklist.bed`)
* Genomic locations which are known to produce artifacts and spurious variants in Browser Extensible Data (BED) format.


***


=== Getting Started: Specify the input data with parameters.
We can begin writing the pipeline by creating and editing a text file called `main.nf`
from the `ngs2017-nf` repository directory with your favourite text editor. In this example we are using nano:

----
$ nano main.nf
----

We edit can edit this file to specify the default parameters.

----
/*
 * Define the default parameters <1>
 */

params.genome     = "$baseDir/data/genome.fa" <2>
params.variants   = "$baseDir/data/known_variants.vcf.gz"
params.blacklist  = "$baseDir/data/blacklist.bed"
params.reads      = "$baseDir/data/reads/rep1_{1,2}.fq.gz" <3>
params.results    = "results" <4>
params.gatk       = '/usr/local/bin/GenomeAnalysisTK.jar' <5>
----

TIP: With `nano` you can paste the above text into your `main.nf` script with the `shift`+`insert` keys.

<1> The `/\*`, `*` and `*/` specify comment lines which are ignored by Nextflow.

<2> The variable `$baseDir` specifies the base directory of the pipeline, in this case the directory `ngs2017-nf`.

<3> The `reads` parameter uses parameter expansion to specify the forward (`rep1_1.fq.gz`) and reverse (`rep1_2.fq.gz`) reads are pairs of the same sample.

<4> The `results` parameter is used to specify a directory called `results`.

<5> The `gatk` parameter specifies the location of the GATK jar file.

Once you have the default parameters in the `main.nf` file, you can save and run the pipeline for the first time.

TIP: With `nano` you can save and the file with `Ctrl+O`, then `Enter`, followed by `Ctrl+X`.

We run the pipeline with the following command:

----
$ nextflow run main.nf
----

You should see the pipeline launch and then exit.

----
N E X T F L O W  ~  version 0.24.1
Launching `main.nf` [nauseous_wright] - revision: 83a0a5415a
----

***
==== Problem #1
Great, now let get our data into variables and https://www.nextflow.io/docs/latest/channel.html[channels]. Open the `main.nf` file and copy the lines below.

This time you must fill the `BLANK` spaces with the correct constructors.

----
/*
 *  Parse the input parameters
 */

genome_file     = BLANK
variants_file   = BLANK
blacklist_file  = BLANK
reads_ch        = BLANK
GATK            = BLANK
----

TIP: The first three should specify file objects containing a single `file`. For the reads channel, we can use a https://www.nextflow.io/docs/latest/channel.html#channel-factory[channel constructor] for pairs of files. The final one, `GATK` is simply a creating a Nextflow variable specifying the relative path of the GATK file and does not need a constructor.

***

=== Process 1A: Create a FASTA genome index with samtools for GATK

Now we have our inputs set up we can move onto our first process.

In our first process we will create a genome index using http://www.htslib.org/[samtools]

The pseudocode for the process would be:

----
    process:
      1A_prepare_genome_samtools

    synopsis:
      create a genome index for the genome fasta with samtools

    input:
      the genome fasta file

    output:
      the samtools genome index file
----

==== Problem #2
Copy the code below and paste it at the end of `main.nf`.

Your aim is to insert the correct input name from into
the input step (written as `BLANK`) of the process and run the pipeline.

----
/*
 * Process 1A: Create a FASTA genome index with samtools
 */

process '1A_prepare_genome_samtools' { <1>

  input:
      file genome from BLANK <2>

  output:
      file "${genome}.fai" into genome_index_ch <3>

  script:
  """
  samtools faidx ${genome} <4>
  """
}
----

In plain english, the process could be written as:

<1> A **process** called 1A_prepare_genome_samtools

<2> takes as **input** the genome file from `BLANK`

<3> and creates as **output** a genome index file which goes into channel `genome_index_ch`

<4> **script**: using samtools create the genome index from the genome file

***

==== Process 1B: Create a FASTA genome sequence dictionary with Picard for GATK

Our first process created the genome index for GATK using samtools. For the next process we must do something very similar, this time creating a genome sequence dictionary using https://broadinstitute.github.io/picard/[Picard].

The pseudocode for the process would be:

----
    process:
      1B_prepare_genome_picard

    synopsis:
      create a genome dictionary for the genome fasta with Picard tools

    input:
      the genome fasta file

    output:
      the genome dictionary file
----

===== Problem #3

Fill in the `BLANK` words for both the input and output sections.

TIP: You can choose any channel output name that makes sense to you.
----
/*
 * Process 1B: Create a FASTA genome sequence dictionary with Picard for GATK
 */

process '1B_prepare_genome_picard' {

  input:
      file genome BLANK BLANK

  output:
      file "${genome.baseName}.dict" BLANK BLANK

  script:
  """
  PICARD=`which picard.jar`
  java -jar \$PICARD CreateSequenceDictionary R= $genome O= ${genome.baseName}.dict
  """
}
----

NOTE: `.baseName` returns the filename without the file suffix. If `"${genome}"` is `human.fa`, then `"${genome.baseName}.dict"` would be `human.dict`.

***

==== Process 1C: Create STAR genome index file

Next we must create a genome index for the https://github.com/alexdobin/STAR[STAR] mapping software.

The pseudocode for the process would be:

----
    process:
      1C_prepare_star_genome_index

    synopsis:
      create a STAR genome index for the genome fasta

    input:
      the genome fasta file

    output:
      a directory containing the STAR genome index
----

===== Problem #4

This is a similar exercise as problem 3, except this time both `input` and `output` lines have been left completely `BLANK` and must be completed.

----
/*
 * Process 1C: Create the genome index file for STAR
 */

process '1C_prepare_star_genome_index' {

  input:
      BLANK_LINE

  output:
      BLANK_LINE

  script:
  """
  mkdir genome_dir

  STAR --runMode genomeGenerate \
       --genomeDir genome_dir \
       --genomeFastaFiles ${genome} \
       --runThreadN ${task.cpus}
  """
}
----

TIP: The output of the STAR genomeGenerate command is specified here as `genome_dir`.

==== Process 1D: Create a file containing the filtered and recoded set of variants

Next on to something a little more tricky.

The next process takes two inputs: the variants file and the blacklist file.

It should output a channel named `prepared_vcf_ch` which contains a tuple of two files.

NOTE: In Nextflow, tuples can be defined in the input or output using the https://www.nextflow.io/docs/latest/process.html?highlight=set#output-set-of-values[`set`] qualifier.

The pseudocode for the process would be:

----
    process:
      1D_prepare_vcf_file

    synopsis:
      Create a filtered and recoded set of variants

    input:
      the variants file
      the blacklisted regions file

    output:
      a set containing the filtered/recoded VCF file and the tab index (TBI) file.
----

===== Problem #5

You must fill in the two `BLANK_LINES` in the input and the two `BLANK` output files.

----
/*
 * Process 1D: Create a file containing the filtered and recoded set of variants
 */

process '1D_prepare_vcf_file' {

  input:
      BLANK_LINE
      BLANK_LINE

  output:
      set(BLANK,BLANK) into prepared_vcf_ch

  script:
  """
  vcftools --gzvcf $variantsFile -c \ <1>
           --exclude-bed ${blacklisted} \ <2>
           --recode | bgzip -c \
           > ${variantsFile.baseName}.filtered.recode.vcf.gz <3>

  tabix ${variantsFile.baseName}.filtered.recode.vcf.gz <4>
  """
}
----
<1> The input variable for the variants file
<2> The input variable for the blacklist file
<3> The first of the two output files
<4> Generates the second output file named `"${variantsFile.baseName}.filtered.recode.vcf.gz.tbi"`

Congratulations! Part 1 is now complete.

Try run the pipeline from the project directory with:

```
$ nextflow run main.nf
```

***

We have all the data prepared and into channels ready for the more serious steps

==== Process 2: STAR Mapping

In this process, for each sample, we align the reads to our genome using the STAR index we created previously.

The process could be summerised in pseudocode as:

----
    process:
      2_rnaseq_mapping_star

    synopsis:
      mapping of the RNA-Seq reads using STAR

    input:
      the genome fasta file
      the STAR genome index
      a set containing the sample id and paired read files

    output:
      a set containg sample id, aligned bam file & aligned bam file index
----

===== Problem #6

You must fill in the three `BLANK_LINE` lines in the input and the one `BLANK_LINE` line in the output.

----
/*
 * Process 2: Align RNA-Seq reads to the genome with STAR
 */

process '2_rnaseq_mapping_star' {

  input:
      BLANK_LINE
      BLANK_LINE
      BLANK_LINE

  output:
      BLANK_LINE

  script:
  """
  # ngs-nf-dev Align reads to genome
  STAR --genomeDir $genomeDir \
       --readFilesIn $reads \
       --runThreadN ${task.cpus} \
       --readFilesCommand zcat \
       --outFilterType BySJout \
       --alignSJoverhangMin 8 \
       --alignSJDBoverhangMin 1 \
       --outFilterMismatchNmax 999

  # 2nd pass (improve alignmets using table of splice junctions and create a new index)
  mkdir genomeDir
  STAR --runMode genomeGenerate \
       --genomeDir genomeDir \
       --genomeFastaFiles $genome \
       --sjdbFileChrStartEnd SJ.out.tab \
       --sjdbOverhang 75 \
       --runThreadN ${task.cpus}

  # Final read alignments
  STAR --genomeDir genomeDir \
       --readFilesIn $reads \
       --runThreadN ${task.cpus} \
       --readFilesCommand zcat \
       --outFilterType BySJout \
       --alignSJoverhangMin 8 \
       --alignSJDBoverhangMin 1 \
       --outFilterMismatchNmax 999 \
       --outSAMtype BAM SortedByCoordinate \
       --outSAMattrRGline ID:$replicateId LB:library PL:illumina PU:machine SM:GM12878

  # Index the BAM file
  samtools index Aligned.sortedByCoord.out.bam
  """
}
----

TIP: The final command produces an bam index which is the file name with `.bai` attached.

***

The next step is a filtering step using GATK. For each sample, we split all the reads that contain
N characters in their http://genome.sph.umich.edu/wiki/SAM#What_is_a_CIGAR.3F[CIGAR] string.

==== Process 3: GATK Split on N

The process creates k+1 new reads (where k is the number of N cigar elements)
that correspond to the segments of the original read beside/between
the splicing events represented by the Ns in the original CIGAR.

The process could be summerised in pseudocode as:

----
    process:
      3_rnaseq_gatk_splitNcigar

    synopsis:
      split reads on N in CIGAR using GATK

    input:
      the genome fasta file
      the genome index made with samtools
      the genome dictionary made with picard
      a set containg sample id, aligned bam file and aligned bam file index from the STAR mapping

    output:
      a set containing the sample id, the split bam file and the split bam index file

----

===== Problem #7

You must fill in the four `BLANK_LINE` lines in the input and the one `BLANK_LINE` line in the output.

CAUTION: There is an optional https://www.nextflow.io/docs/latest/process.html#tag[`tag`] line added
to the start of this process. The https://www.nextflow.io/docs/latest/process.html#tag[`tag`] line allows you to assign a name to a specific
task (single execution of a process). This is particularly useful when there are many samples all
using the same process.

----
process '3_rnaseq_gatk_splitNcigar' {
  tag OPTIONAL_BLANK

  input:
      BLANK_LINE
      BLANK_LINE
      BLANK_LINE
      BLANK_LINE

  output:
      BLANK_LINE

  script:
  """
  # SplitNCigarReads and reassign mapping qualities
  java -jar $GATK -T SplitNCigarReads \
                  -R $genome -I $bam \
                  -o split.bam \
                  -rf ReassignOneMappingQuality \
                  -RMQF 255 -RMQT 60 \
                  -U ALLOW_N_CIGAR_READS \
                  --fix_misencoded_quality_scores
  """
}
----

TIP: The GATK command above automatically creates a bam index (.bai) of the split.bam output file

***

Next we perform a Base Quality Score Recalibration step using GATK.

==== Process 4: GATK Recalibrate

This step uses GATK to detect systematic errors in the base quality scores, select unique alignments and then index the resulting bam file with samtools. You can find details of the specific GATK BaseRecalibrator parameters https://software.broadinstitute.org/gatk/gatkdocs/3.6-0/org_broadinstitute_gatk_tools_walkers_bqsr_BaseRecalibrator.php[here].

The process could be summerised in pseudocode as:

----
    process:
      4_rnaseq_gatk_recalibrate

    synopsis:
      recalibrate reads from each replicate using GATK

    input:
      the genome fasta file
      the genome index made with samtools
      the genome dictionary made with picard
      a set containg replicate id, aligned bam file and aligned bam file index from process 3
      a set containing the filtered/recoded VCF file and the tab index (TBI) file from process 1D

    output:
      a set containing the sample id, the unique bam file and the unique bam index file <1>

----
<1> The files resulting from this process will be used in two downstream processes. If a process is executed more than once, and the downstream channel is used by more than one process, we must duplicate the channel. We can do this using the `into` operator with parenthesis in the output section. See https://www.nextflow.io/docs/latest/operator.html#into[here] for more information on using `into`. 

===== Problem #8

You must fill in the four `BLANK_LINE` lines in the input and the one `BLANK_LINE` line in the output.

----
process '4_rnaseq_gatk_recalibrate' {
  tag "$replicateId"
    
  input: 
      BLANK_LINE
      BLANK_LINE
      BLANK_LINE
      BLANK_LINE
      BLANK_LINE

  output:
      BLANK into (final_output_ch, bam_for_ASE_ch)

  script: 
    sampleId = replicateId.replaceAll(/[12]$/,'')
    """
    # Indel Realignment and Base Recalibration
    java -jar $GATK -T BaseRecalibrator \
                  --default_platform illumina \
                  -cov ReadGroupCovariate \
                  -cov QualityScoreCovariate \
                  -cov CycleCovariate \
                  -knownSites ${variants_file} \
                  -cov ContextCovariate \
                  -R ${genome} -I ${bam} \
                  --downsampling_type NONE \
                  -nct ${task.cpus} \
                  -o final.rnaseq.grp 

     java -jar $GATK -T PrintReads \
                  -R ${genome} -I ${bam} \
                  -BQSR final.rnaseq.grp \
                  -nct ${task.cpus} \
                  -o final.bam

    # Select only unique alignments, no multimaps
    (samtools view -H final.bam; samtools view final.bam| grep -w 'NH:i:1') \
    |samtools view -Sb -  > ${replicateId}.final.uniq.bam <1>

    # Index BAM files
    samtools index ${replicateId}.final.uniq.bam <2>
    """
}

----

<1> The unique bam file
<2> The index of the unique bam file (bam file name + `.bai`)

***

Now we are ready to perform the variant calling with GATK.



==== Process 5: GATK Variant Calling

This steps call variants with GATK HaplotypeCaller. 

You can find details of the specific GATK HaplotypeCaller parameters https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_gatk_tools_walkers_haplotypecaller_HaplotypeCaller.php[here]. 

The process could be summerised in pseudocode as:

----
    process:
      5_rnaseq_call_variants

    synopsis:
      variant calling of each sample using GATK

    input:
      the genome fasta file
      the genome index made with samtools
      the genome dictionary made with picard
      a set containg replicate id, aligned bam file and aligned bam file index from process 3
      a set containing the filtered/recoded VCF file and the tab index (TBI) file from process 1D

    output:
      a set containing the sample id the resulting variant calling file (vcf) <1>
----

===== Problem #9

In this problem we will introduce the use of a channel operator in the input section. By default, the https://www.nextflow.io/docs/latest/operator.html#grouptuple[`groupTuple()`] operator groups items which share the same first element of the set.

CAUTION: Note that in process 4, we used the sampleID (not replicateID) as the first element of the set in the output. Now we combine the replicates by grouping them on the sample ID. It follows from this that process 4 is run one time per replicate and process 5 is run one time per sample.

Fill in the `BLANKS` as before.

----
process '5_rnaseq_call_variants' {
  tag BLANK

  input:
      BLANK_LINE
      BLANK_LINE
      BLANK_LINE
      BLANK from BLANK.groupTuple()
  
  output: 
      BLANK_LINE

  script:
  """
  echo "${bam.join('\n')}" > bam.list
  
  # Variant calling
  java -jar $GATK -T HaplotypeCaller \
                  -R $genome -I bam.list \
                  -dontUseSoftClippedBases \
                  -stand_call_conf 20.0 \
                  -o output.gatk.vcf.gz

  # Variant filtering
  java -jar $GATK -T VariantFiltration \
                  -R $genome -V output.gatk.vcf.gz \
                  -window 35 -cluster 3 \
                  -filterName FS -filter "FS > 30.0" \
                  -filterName QD -filter "QD < 2.0" \
                  -o final.vcf
  """
}
----

***



==== Processes 6A and 6B: 

In the final steps we will create processes for Allele-Specific Expression and RNA Editing Analysis.


Post-process the VCF result, you can find 


Prepare variants file for allele specific expression (ASE) analysis


The psuedocode for these processes could be written as:

----
    process:
      6A_post_process_vcf

    synopsis:
      post-process the variant calling file (vcf) of each sample

    input:
      set containing the sample ID and vcf file
      a set containing the filtered/recoded VCF file and the tab index (TBI) file from process 1D

    output:
      a set containing the sample id, the variant calling file (vcf) and a file containing common SNPs 


    process:
      6B_prepare_vcf_for_ase

    synopsis:
      prepare the VCF for allele specific expression (ASE) and generate a figure in R.

    input:
      a set containing the sample id, the variant calling file (vcf) and a file containing common SNPs

    output:
      a set containing the sample ID and known SNPs in the sample for ASE 
      a figure of SNPs generated in R as a PDF file

----

===== Problem #10

Here we introduce the `publishDir` directive.

You must also now combine the output of process 6A with the input of process 6B.

----
process '6A_post_process_vcf' {
  tag BLANK
  publishDir "$params.results/$sampleId" <1>
  
  input:
      BLANK_LINE
      BLANK_LINE
      
  output: 
      BLANK_LINE
  
  script:
  '''
  grep -v '#' final.vcf | awk '$7~/PASS/' |perl -ne 'chomp($_); ($dp)=$_=~/DP\\=(\\d+)\\;/; if($dp>=8){print $_."\\n"};' > result.DP8.vcf
  
  vcftools --vcf result.DP8.vcf --gzdiff filtered.recode.vcf.gz  --diff-site --out commonSNPs
  '''
}


process '6B_prepare_vcf_for_ase' {
  tag BLANK
  publishDir BLANK
  
  input: 
      BLANK_LINE
  output: 
      BLANK_LINE
      BLANK_LINE

  script:
  '''
  awk 'BEGIN{OFS="\t"} $4~/B/{print $1,$2,$3}' commonSNPs.diff.sites_in_files  > test.bed
    
  vcftools --vcf final.vcf --bed test.bed --recode --keep-INFO-all --stdout > known_snps.vcf

  grep -v '#'  known_snps.vcf | awk -F '\\t' '{print $10}' \
               |awk -F ':' '{print $2}'|perl -ne 'chomp($_); \
               @v=split(/\\,/,$_); if($v[0]!=0 ||$v[1] !=0)\
               {print  $v[1]/($v[1]+$v[0])."\\n"; }' |awk '$1!=1' \
               >AF.4R

  gghist.R -i AF.4R -o AF.histogram.pdf
  '''
}
---- 

***
The final step is the GATK ASEReadCounter. But before we can 


===== Problem #11

Now we have seen all the basics of processes in Nextflow. However, one of the standout features of Nextflow is the operations that can be performed on channels outside of processes.

We which to have 

You can fill in the `BLANKS` below.

----
bam_for_ASE_ch
  .BLANK                            <1>
  .phase(vcf_for_ASE)               <2>
  .map{ left, right ->              <3>
    def repID = left[0]             <4>
    def bam   = left[1]             <5>
    def bai   = left[2]             <6>
    def vcf   = right [1]           <7>
    tuple(BLANK,BLANK,BLANK,BLANK)  <8>
  .set { grouped_vcf_bam_bai_ch }   <9>

----
<1> an operator that groups sets that contain a common first element.
<2> the phase operator synchronizes the values emitted by two other channels. See https://www.nextflow.io/docs/latest/operator.html?phase#phase[here] for more details
<3> the map operator can apply any function to every item on a channel. In this case we take our tuple from the phase operation, define the seperate elements and create a new tuple.
<4> define repID to be the first element of left.
<5> define bam to be the second element of left.
<6> define bai to be the third element of left.
<7> define vcf to be the first element of right.
<8> create a new tuple made of four elements
<9> rename the resulting as `grouped_vcf_bam_bai_ch`

CAUTION: `left` and `right` above are arbitary names. From the phase operator documentation, we see that phase returns pairs of items. So here `left` originates from contents of the `bam_for_ASE_ch` channel and `right` originates from the contents of `vcf_for_ASE` channel.

***

==== Process 6C: Allele-Specific Expression analysis with GATK ASEReadCounter

Now we have t


===== Problem #12


In the final problem you can 

The process creates a file called `ASE.tsv` as output and needs as input:

1. genome fasta file
2. genome index file from samtools
3. genome dictionary file
4. the `grouped_vcf_bam_bai_ch`channel

You will need to contruct the rest of the process yourself.
  
----
  echo "${bam.join('\n')}" > bam.list
    
  java -jar $GATK -R ${genome} \
                  -T ASEReadCounter \
                  -o ASE.tsv \
                  -I bam.list \
                  -sites ${vcf}
----

Congratulations, you have now finished!

***
