= Nextflow Implementaton

== PART 1: Data preparation

A first step in any pipeline is to prepare the input data. You will find 
all the data required to run the pipeline in the folder `data` 
within the `ngs2017-nf` repository directory. 

There are four data inputs that we will use in this tutorial:

. *Genome File* (`data/genome.fa`)
* Human chromosome 22 in FASTA file format

. *Read Files* (`data/reads/`)
* Sample 1: 50 bp paired-end reads (`rep1_1.fq.gz` and `rep1_2.fq.gz`).

. *Variants File* (`data/known_variants.vcf.gz`)
* Known variants, gunzipped as a Variant Calling File (VCF) format.

. *Blacklist File* (`data/blacklist.bed`)
* Genomic locations which are known to produce artifacts and spurious variants in Browser Extensible Data (BED) format.


***


=== Getting Started: Specify the input data with parameters.
We can begin writing the pipeline by creating and editing a text file called `main.nf`
from the `ngs2017-nf` repository directory with your favourite text editor. In this example we are using nano:

----
$ nano main.nf
----

We edit can edit this file to specify the default parameters.

----
/*
 * Define the default parameters <1>
 */

params.genome     = "$baseDir/data/genome.fa" <2>
params.variants   = "$baseDir/data/known_variants.vcf.gz"
params.blacklist  = "$baseDir/data/blacklist.bed"
params.reads      = "$baseDir/data/reads/rep1_{1,2}.fq.gz" <3>
params.results    = "results" <4>
params.gatk       = '/usr/local/bin/GenomeAnalysisTK.jar' <5>
----

TIP: With `nano` you can paste the above text into your `main.nf` script with the `shift`+`insert` keys.

<1> The `/\*`, `*` and `*/` specify comment lines which are ignored by Nextflow.

<2> The variable `$baseDir` specifies the base directory of the pipeline, in this case the directory `ngs2017-nf`.

<3> The `reads` parameter uses parameter expansion to specify the forward (`rep1_1.fq.gz`) and reverse (`rep1_2.fq.gz`) reads are pairs of the same sample.

<4> The `results` parameter is used to specify a directory called `results`.

<5> The `gatk` parameter specifies the location of the GATK jar file.


Once you have the default parameters in the `main.nf` file, you can save and run the pipeline for the first time.

TIP: With `nano` you can save and the file with `Ctrl+O`, then `Enter`, followed by `Ctrl+X`.

We run the pipeline with the following command:

----
$ nextflow run main.nf
----

You should see the pipeline launch and then exit.

----
N E X T F L O W  ~  version 0.24.1
Launching `main.nf` [nauseous_wright] - revision: 83a0a5415a
----

***
=== Problem #1
Great, now let get our data into variables and https://www.nextflow.io/docs/latest/channel.html[channels]. Open the `main.nf` file and copy the lines below.

This time you must fill the `BLANK` spaces with the correct constructors.

----
/*
 *  Parse the input parameters
 */

genome_file     = BLANK
variants_file   = BLANK
blacklist_file  = BLANK
reads_ch        = BLANK
GATK            = BLANK
----

TIP: The first three should specify file objects containing a single `file`. For the reads channel, we can use a ttps://www.nextflow.io/docs/latest/channel.html#channel-factory[channel contructor] for pairs of files. The final one, `GATK` is simply a creating a Nextflow variable specifying the relative path of the GATK file and does not need a constructor.


*link:solutions/solution_01.adoc[Problem #1 Solution]*


***

==== Process 1A: Create a FASTA genome index with samtools for GATK

Now we have our inputs set up we can move onto our first process. 

In our first process we will create a genome index using http://www.htslib.org/[samtools]

Copy the code below and paste it at the end of `main.nf`.

=== Problem #2
Your aim is to insert the correct input name from above into
the input step (written as `BLANK`) of the process and run the pipeline.

----
/*
 * Process 1A: Create a FASTA genome index with samtools
 */

process '1A_prepare_genome_samtools' { <1>

  input: 
      file genome from BLANK <2>
      
  output:
      file "${genome}.fai" into genome_index_ch <3>
      
  script:
  """
  samtools faidx ${genome} <4>
  """
}
----

In plain english the process could be written as:


<1> A **process** called 1A_prepare_genome_samtools

<2> takes as **input** the genome file from `BLANK`

<3> and creates as **output** a genome index file which goes into channel `genome_index_ch`

<4> **script**: using samtools create the genome index from the genome file

*link:solutions/solution_02.adoc[Problem #2 Solution]*

Now we have out first process finished!

***

==== Process 1B: Create a FASTA genome sequence dictionary with Picard for GATK

Our first process created the genome index for GATK using samtools. For the next process we must do something very similar, this time creating a genome sequence dictionary using https://broadinstitute.github.io/picard/[Picard].

=== Problem #3

Fill in the `BLANK` words for both the input and output sections. 

----
/*
 * Process 1B: Create a FASTA genome sequence dictionary with Picard for GATK
 */

process '1B_prepare_genome_picard' {

  input:
      file genome BLANK BLANK
      
  output:
      file "${genome.baseName}.dict" BLANK BLANK

  script:
  """
  PICARD=`which picard.jar`
  java -jar \$PICARD CreateSequenceDictionary R= $genome O= ${genome.baseName}.dict
  """
}
----

NOTE: `.baseName` returns the filename without the file suffix. If `"${genome}"` is `human.fa`, then `"${genome.baseName}.dict"` is `human.dict`.

***

*link:solutions/solution_03.adoc[Problem #3 Solution]*

==== Process 1C: Create STAR genome index file

Next we must create a genome index for the https://github.com/alexdobin/STAR[STAR] mapping software. 

=== Problem #4

This is a similar exercise except this time both `input` and `output` sections have been left completely `BLANK`and must be completed.

----
/*
 * Process 1C: Create the genome index file for STAR
 */

process '1C_prepare_star_genome_index' {

  input:
      BLANK
      
  output:
      BLANK

  script:
  """
  mkdir genome_dir

  STAR --runMode genomeGenerate \
       --genomeDir genome_dir \
       --genomeFastaFiles ${genome} \
       --runThreadN ${task.cpus}
  """
}
----

TIP: The output of the STAR genomeGenerate command is `genome_dir`.

*link:solutions/solution_04.adoc[Problem #4 Solution]*

==== Process 1D: Create a file containing the filtered and recoded set of variants

=== PART 2: STAR RNA-Seq Mapping

==== Process 2: Align RNA-Seq reads to the genome with STAR

== PART 3: GATK Prepare Mapped Reads

=== Process 3: Split reads that contain Ns in their CIGAR string

== PART 4: GATK Base Quality Score Recalibration Workflow

=== Process 4: Base recalibrate to detect systematic errors in base quality scores, select unique alignments and index

== PART 5: GATK Variant Calling

=== Process 5: Call variants with GATK HaplotypeCaller

== PART 6: Post-process variants file and prepare for Allele-Specific Expression and RNA Editing Analysis

=== Process 6A: Post-process the VCF result

=== Process 6B: Prepare variants file for allele specific expression (ASE) analysis

=== Process 6C: Allele-Specific Expression analysis with GATK ASEReadCounter
